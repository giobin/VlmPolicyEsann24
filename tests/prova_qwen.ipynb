{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to sys.path: ['/data01/gbonetta/rocket', '/data01/gbonetta/rocket/src']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gbonetta/miniconda3/envs/crafter_smart/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.5.2 (SDL 2.28.2, Python 3.10.13)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '3'\n",
    "os.environ['HF_HOME'] = '<PATH_TO>'\n",
    "\n",
    "rocket_dir = os.path.split(os.path.abspath(os.curdir))[:-1]\n",
    "rocket_src_dir = os.path.join(*rocket_dir, 'src')\n",
    "rocket_dir = os.path.join(*rocket_dir)\n",
    "\n",
    "print(f'Appending to sys.path:', [rocket_dir, rocket_src_dir])\n",
    "\n",
    "sys.path.append(rocket_dir)\n",
    "sys.path.append(rocket_src_dir)\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import copy\n",
    "import gymnasium\n",
    "\n",
    "from PIL import Image\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    AutoConfig,\n",
    "    GPTQConfig\n",
    ")\n",
    "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\n",
    "\n",
    "from torch.distributions.categorical import Categorical\n",
    "from accelerate import Accelerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions.categorical import Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOCAL_NUM_ENVS = 1\n",
    "SEED = 1234\n",
    "MODEL='giobin/Qwen-VL-Chat-Int4-fromImageList' #\"Qwen/Qwen-VL-Chat-Int4\"\n",
    "torch.cuda.manual_seed = SEED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<action_enum.forward: 'move forward'>, <action_enum.pickup: 'pick up'>, <action_enum.toggle: 'toggle'>, <action_enum.opt_left: 'move left'>, <action_enum.opt_right: 'move right'>, <action_enum.opt_back: 'move back'>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gbonetta/miniconda3/envs/crafter_smart/lib/python3.10/site-packages/gymnasium/envs/registration.py:694: UserWarning: \u001b[33mWARN: Overriding environment FrozenLakeText-v0 already in registry.\u001b[0m\n",
      "  logger.warn(f\"Overriding environment {new_spec.id} already in registry.\")\n",
      "/home/gbonetta/miniconda3/envs/crafter_smart/lib/python3.10/site-packages/gymnasium/envs/registration.py:694: UserWarning: \u001b[33mWARN: Overriding environment Hanoi3Disk-v0 already in registry.\u001b[0m\n",
      "  logger.warn(f\"Overriding environment {new_spec.id} already in registry.\")\n",
      "/home/gbonetta/miniconda3/envs/crafter_smart/lib/python3.10/site-packages/gymnasium/envs/registration.py:694: UserWarning: \u001b[33mWARN: Overriding environment Hanoi4Disk-v0 already in registry.\u001b[0m\n",
      "  logger.warn(f\"Overriding environment {new_spec.id} already in registry.\")\n",
      "/home/gbonetta/miniconda3/envs/crafter_smart/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.width to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.width` for environment variables or `env.get_wrapper_attr('width')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/gbonetta/miniconda3/envs/crafter_smart/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.height to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.height` for environment variables or `env.get_wrapper_attr('height')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    }
   ],
   "source": [
    "is_crafter = False \n",
    "from src.environments.minigrid_env import make_minigrid_env\n",
    "runs_directory = 'runs_directory_prova'\n",
    "envs = gymnasium.vector.SyncVectorEnv(\n",
    "            [make_minigrid_env(\n",
    "                runs_directory,\n",
    "                'MiniGrid-DoorKey-8x8-v0', #'MiniGrid-Fetch-8x8-N3-v0',#'MiniGrid-DoorKey-5x5-v0', #'MiniGrid-LockedRoom-v0','MiniGrid-LavaGapS7-v0', 'MiniGrid-PutNear-8x8-N3-v0', #'MiniGrid-PutNear-8x8-N3-v0','MiniGrid-BlockedUnlockPickup-v0', 'MiniGrid-LavaCrossingS11N5-v0', 'MiniGrid-DoorKey-8x8-v0' 'MiniGrid-SimpleCrossingS11N5-v0' 'MiniGrid-LavaCrossingS9N3-v0' 'MiniGrid-SimpleCrossingS11N5-v0'\n",
    "                possible_actions_list=['forward','pickup','toggle','opt_left','opt_right','opt_back'],  #left right forward pickup toggle\n",
    "                fov=1,\n",
    "                fixed_orientation=False,\n",
    "                no_step_description=False,\n",
    "                seed=1 + i *100,\n",
    "                save_video=False,\n",
    "                save_video_every=100,\n",
    "                save_stats=False\n",
    "            )\n",
    "            for i in range(1)\n",
    "            ])\n",
    "\n",
    "action_enum = envs.envs[0].action_enum\n",
    "print(list(action_enum))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using `disable_exllama` is deprecated and will be removed in version 4.37. Use `use_exllama` instead and specify the version with `exllama_config`.The value of `use_exllama` will be overwritten by `disable_exllama` passed in `GPTQConfig` or stored in your config file.\n",
      "/home/gbonetta/miniconda3/envs/crafter_smart/lib/python3.10/site-packages/transformers/quantizers/auto.py:155: UserWarning: You passed `quantization_config` or equivalent parameters to `from_pretrained` but the model you're loading already has a `quantization_config` attribute. The `quantization_config` from the model will be used.However, loading attributes (e.g. ['use_cuda_fp16', 'use_exllama', 'max_input_length', 'exllama_config', 'disable_exllama']) will be overwritten with the one you passed to `from_pretrained`. The rest will be ignored.\n",
      "  warnings.warn(warning_msg)\n",
      "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n",
      "/home/gbonetta/miniconda3/envs/crafter_smart/lib/python3.10/site-packages/transformers/modeling_utils.py:4193: FutureWarning: `_is_quantized_training_enabled` is going to be deprecated in transformers 4.39.0. Please use `model.hf_quantizer.is_trainable` instead\n",
      "  warnings.warn(\n",
      "Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00,  8.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 112,197,632 || all params: 3,292,734,208 || trainable%: 3.407430570235689\n"
     ]
    }
   ],
   "source": [
    "from src.agents.QWen_agent import QWenAgent\n",
    "agent = QWenAgent(MODEL,\n",
    "            action_enum=action_enum, \n",
    "            is_lora=True,\n",
    "            padding_side=\"right\", \n",
    "            num_prompt_images=1, \n",
    "            use_text_description=True, \n",
    "            gradient_ckpt=False)\n",
    "agent.network.to('cuda')\n",
    "agent.critic.to('cuda')\n",
    "\n",
    "action_to_string = [a.value for a in action_enum]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_inference(value_prompt_template, action_template, temperature, steps, print_logs=100):\n",
    "    \n",
    "    tot_reward = 0\n",
    "\n",
    "    next_obs, infos = envs.reset(seed=SEED)\n",
    "    next_obs = torch.Tensor(next_obs).to('cuda')\n",
    "    next_text_obs = infos.get('obs', [None]*LOCAL_NUM_ENVS)\n",
    "\n",
    "    for step in range(steps):\n",
    "        with torch.no_grad():\n",
    "            res = agent.get_action_and_value(next_obs, \n",
    "                                                    value_prompt_template=value_prompt_template,\n",
    "                                                    action_template=action_template,\n",
    "                                                    text_description=next_text_obs, \n",
    "                                                    temperature=temperature, \n",
    "                                                    generate_actions=True,\n",
    "                                                    normalization_by_words=False,\n",
    "                                                    use_full_seq_logits=True,\n",
    "                                                    advanced_action_matching=False)\n",
    "            action, logprob, value = res['action'], res['log_prob'], res['values']\n",
    "\n",
    "            to_pil = transforms.ToPILImage()\n",
    "            pil_image = to_pil(transforms.functional.invert(next_obs[0].permute(2, 0, 1)))\n",
    "\n",
    "            best_action = action.cpu().numpy()\n",
    "            next_obs, reward, terminations, truncations, infos = envs.step(best_action)\n",
    "            next_text_obs = infos.get('obs', [None]*LOCAL_NUM_ENVS)    \n",
    "            next_obs = torch.Tensor(next_obs).to('cuda')\n",
    "\n",
    "            tot_reward += reward\n",
    "\n",
    "            if step % print_logs == 0:\n",
    "                print(f\"\\n\\n####################################### STEP {step} #######################################\")\n",
    "                print(f\"this is the env image:\\n\")\n",
    "                display(pil_image)\n",
    "                print(f\"-- the prompt describing the image is:\\n\")\n",
    "                print(f\"{res['just_context_prompts']=}\\n\")\n",
    "                print(f\"-- the prompt augmented with the first action description is:\\n\")\n",
    "                print(f\"{res['prompts'][0]=}\\n\")\n",
    "                print(f\"-- given this situation the agent \\'randomly\\' chose:\\n\")\n",
    "                print(f\"action number: {best_action} -> {action_to_string[best_action.item()]}\")\n",
    "                print(f\"-- the actual action logits were:\\n\")\n",
    "                print(f\"{res['action_logits']}\\n\") \n",
    "                print(f\"{res['log_prob']}\\n\") \n",
    "                print(f\"-- performing the action {best_action} in the env, resulted this:\\n\")\n",
    "                print(f\"reward: {reward}, terminations: {terminations}, truncations: {truncations}\\n\")\n",
    "                print(f\"total reward: {tot_reward}\\n\")\n",
    "    return tot_reward\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_steps = 100\n",
    "TEMPERATURE = 'max_logit' #'max_logit'\n",
    "#value_prompt_template = \"<|im_start|>system\\nYou are a helpful assistant.<|im_end|>\\n<|im_start|>user\\nPicture 1: <img>/placeholder_frame.png</img>\\nYou are an agent in a minigrid game.\\nRules:\\nyou can pick up the key only if it is 1 step ahead of you {}\\nWhat's the next best action? Possible actions are:\\n- go forward\\n- pick up\\n- toggle\\n- move left\\n- move right\\n- move back\\n\\nGame rules:\\n- you can pick up the key only if it is 1 step ahead of you.\\n- the toggle action may serve to open the door.<|im_end|>\\n<|im_start|>assistant\\n\"\n",
    "#value_prompt_template = \"<|im_start|>system\\nYou are a helpful assistant.<|im_end|>\\n<|im_start|>user\\nPicture 1: <img>/placeholder_frame.png</img>\\nYou are an agent in a minigrid game.\\n {}\\nWhat's the next best action? Possible actions are:\\n- move forward\\n- pick up\\n- toggle\\n- move left\\n- move right\\n- move back\\n\\nGame rules:\\n- you can pick up the key only if it is 1 step ahead of you.\\n- the toggle action may serve to open the door.<|im_end|>\\n<|im_start|>assistant\\n\"\n",
    "value_prompt_template = \"<|im_start|>system\\nYou are a helpful assistant.<|im_end|>\\n<|im_start|>user\\nPicture 1: <img>/placeholder_frame.png</img>\\nYou are the red triangle in this minigrid game.\\n {}\\nGame rules:\\n- you can pick up the key only if it is 1 step ahead of you.\\n- the toggle action may serve to open the door.\\nWhat's the next best action?<|im_end|>\\n<|im_start|>assistant\\n\"\n",
    "action_template= \"Based on the given information, the next best action would be to {}\"\n",
    "\n",
    "tot_reward = test_inference(value_prompt_template=value_prompt_template,\n",
    "            action_template=action_template,\n",
    "            temperature=TEMPERATURE,\n",
    "            steps=tot_steps,\n",
    "            print_logs=100)\n",
    "\n",
    "print(f\"TOTAL REWARD -> {tot_reward=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "v_s = [\n",
    "    \"<|im_start|>system\\nYou are a helpful assistant.<|im_end|>\\n<|im_start|>user\\nPicture 1: <img>/placeholder_frame.png</img>\\nI am the red triangle in this minigrid game in the picture.\\n {}\\nWhat's the next best action?<|im_end|>\\n<|im_start|>assistant\\n\",\n",
    "    \"<|im_start|>system\\nYou are a helpful assistant.<|im_end|>\\n<|im_start|>user\\nPicture 1: <img>/placeholder_frame.png</img>\\nI am the red triangle in this minigrid game in the picture.\\n {}\\nPossible game actions are:\\n- move forward\\n- pick up\\n- toggle\\n- move left\\n- move right\\n- move back\\nWhat's the next best action?<|im_end|>\\n<|im_start|>assistant\\n\",\n",
    "    \"<|im_start|>system\\nYou are a helpful assistant.<|im_end|>\\n<|im_start|>user\\nPicture 1: <img>/placeholder_frame.png</img>\\nI am the red triangle in this minigrid game in the picture.\\n {}\\nPossible game actions are:\\n- move forward\\n- pick up\\n- toggle\\n- move left\\n- move right\\n- move back\\n\\nGame rules:\\n- I can pick up the key only if it is 1 step ahead of me.\\n- the toggle action may serve to open the door.\\nWhat's the next best action?<|im_end|>\\n<|im_start|>assistant\\n\",\n",
    "    \"<|im_start|>system\\nYou are a helpful assistant.<|im_end|>\\n<|im_start|>user\\nPicture 1: <img>/placeholder_frame.png</img>\\nI am the red triangle in this minigrid game in the picture.\\n#### BEGIN GAME STATE DESCRIPTION ####\\n {}\\n#### END GAME STATE DESCRIPTION ####\\nPossible actions are:\\n- move forward\\n- pick up\\n- toggle\\n- move left\\n- move right\\n- move back\\n\\nGame rules:\\n- I can pick up the key only if it is 1 step ahead of me in the GAME STATE DESCRIPTION\\n- the toggle action may serve to open the door.\\nWhat's the next best action?<|im_end|>\\n<|im_start|>assistant\\n\",\n",
    "    \"<|im_start|>system\\nYou are a helpful assistant.<|im_end|>\\n<|im_start|>user\\nPicture 1: <img>/placeholder_frame.png</img>\\nI am the red triangle in this minigrid game in the picture.\\n#### BEGIN GAME STATE DESCRIPTION ####\\n {}\\n#### END GAME STATE DESCRIPTION ####\\nPossible actions are:\\n- move 1 step forward\\n- pick up the object\\n- toggle the object\\n- move 1 step left\\n- move 1 step right\\n- move 1 step back\\n\\nGame rules:\\n- I can pick up the key only if it is 1 step ahead of me in the game state description\\n- the toggle action may serve to open the door.\\n- if the key is behind me in the game state description, I should move back.\\nWhat's the next best action?<|im_end|>\\n<|im_start|>assistant\\n\"\n",
    "]\n",
    "a_s = [\n",
    "    \" {}\",\n",
    "    \"Based on the given information, the next best action would be to {}\",\n",
    "    \"Based on the image and the given information, the next best action is to {}\"\n",
    "]\n",
    "\n",
    "#all combinations\n",
    "template_combinations = list(itertools.product(v_s, a_s))\n",
    "print(template_combinations)\n",
    "print(len(template_combinations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.use_text_description = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMPERATURE = 'max_logit'\n",
    "TOT_STEPS = 1000\n",
    "\n",
    "for ix, (v,a) in enumerate(template_combinations):\n",
    "    tot_reward = test_inference(value_prompt_template=v,\n",
    "                action_template=a,\n",
    "                temperature=TEMPERATURE,\n",
    "                steps=TOT_STEPS,\n",
    "                print_logs=100)\n",
    "    print(f\"{TOT_STEPS=}, {TEMPERATURE=}\\n{v=}\\n{a=}\\n{tot_reward=}\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Questa cella può essere usata per far generare il modello. Può servire per vedere come creare l'action_template per esempio. o per capire che cosa Qwen capisce dell'immagine.\n",
    "#L'immagine usata è l'ultima che deriva dalla cella sopra dove è stato fatto girare nell'env\n",
    "\n",
    "t = [\"<|im_start|>system\\nYou are a helpful assistant.<|im_end|>\\n<|im_start|>user\\nPicture 1: <img>/placeholder_frame.png</img>\\nYou are the red agent in this minigrid game on the image.\\n\\nYour mission is:\\n\\nuse the key to open the door and then get to the goal.\\nWhat is the next best move?<|im_end|>\\n<|im_start|>assistant\\n\",\n",
    "     \"this is anither prompt\",\n",
    "     \"this is anither prompt\",\n",
    "     \"this is anither asfgdaf asivovnaoa\"]\n",
    "\n",
    "inputs = agent.tokenizer(t, return_tensors='pt',tokenize=False, padding=True).to('cuda')\n",
    "print(inputs)\n",
    "context_prompt_lens = torch.sum(inputs.attention_mask, dim=1)\n",
    "context_split = context_prompt_lens.tensor_split(2)\n",
    "print(len(context_split)) #[1, 288]\n",
    "print(context_split)\n",
    "forward_out = agent.network(**inputs, image_list=None)\n",
    "#print(forward_out)\n",
    "#pred = agent.network.generate(**inputs, image_list=next_obs.permute(0, 3, 1, 2))\n",
    "response = agent.tokenizer.decode(pred.cpu()[0], skip_special_tokens=True)\n",
    "print(response)\n",
    "#response = tokenizer.decode(pred.cpu()[1], skip_special_tokens=True)\n",
    "#print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "crafter_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
